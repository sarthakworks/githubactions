name: Code Review with DeepSeek-Coder R1

on:
  push:
    branches:
      - main

jobs:
  code-review:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install torch transformers accelerate sentencepiece

      - name: Install Git LFS
        run: |
          sudo apt-get install git-lfs
          git lfs install

      - name: Cache DeepSeek-Coder R1 Model
        id: cache-model
        uses: actions/cache@v3
        with:
          path: deepseek-r1
          key: deepseek-r1-model-v1
          restore-keys: |
            deepseek-r1-model-v1

      - name: Download DeepSeek-Coder R1 Model (Fallback to Hugging Face)
        if: steps.cache-model.outputs.cache-hit != 'true'
        run: |
          mkdir -p deepseek-r1
          cd deepseek-r1
          echo "Attempting to download model from Hugging Face..."
          git lfs install
          git clone https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-base
          cd deepseek-coder-1.3b-base

      - name: Get changed files
        id: changed-files
        run: |
          git fetch origin
          git diff --name-only origin/main...$GITHUB_SHA > changed_files.txt
          cat changed_files.txt

      - name: Run Code Review
        run: |
          python -c "
          from transformers import AutoModelForCausalLM, AutoTokenizer;
          model_path = './deepseek-r1/deepseek-coder-1.3b-base';  # Path to model directory
          tokenizer = AutoTokenizer.from_pretrained(model_path);
          model = AutoModelForCausalLM.from_pretrained(model_path, device_map='auto');
          
          files_to_review = []
          with open('changed_files.txt', 'r') as f:
              files_to_review = f.read().splitlines()

          for file in files_to_review:
              with open(file, 'r') as f:
                  code = f.read();
              inputs = tokenizer(f'Review the following code for best practices:\n\n{code}', return_tensors='pt').to('cuda');
              outputs = model.generate(**inputs, max_new_tokens=512);
              print(tokenizer.decode(outputs[0], skip_special_tokens=True))
          "

      - name: Post Code Review to Commit
        run: |
          COMMIT_SHA=$GITHUB_SHA
          COMMENT="Code review complete! Check the output above for suggestions."
          curl -X POST \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -d "{\"body\": \"$COMMENT\"}" \
            https://api.github.com/repos/${{ github.repository }}/commits/$COMMIT_SHA/comments
